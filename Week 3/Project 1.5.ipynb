{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "HA_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Hank Aaron Stats.csv\")\n",
    "BB_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Barry Bonds Stats.csv\")\n",
    "TC_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Ty Cobb Stats.csv\")\n",
    "WM_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Willie Mays Stats.csv\")\n",
    "SM_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Stan Musial Stats.csv\")\n",
    "AP_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Albert Pujols Stats.csv\")\n",
    "PR_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Pete Rose Stats.csv\")\n",
    "BR_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Babe Ruth Stats.csv\")\n",
    "HW_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Honus Wagner Stats.csv\")\n",
    "TW_df = pd.read_csv(r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\\Ted Williams Stats.csv\")\n",
    "\n",
    "Player_DF_List = [HA_df, BB_df, TC_df, WM_df, SM_df, AP_df, PR_df, BR_df, HW_df, TW_df]\n",
    "all_player_dfs = []\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "merged_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 429-430: truncated \\UXXXXXXXX escape (1321907489.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 429-430: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# CSV files to pull desired data\n",
    "files = {\n",
    "    \"HA\": \"Hank Aaron Stats.csv\",\n",
    "    \"BB\": \"Barry Bonds Stats.csv\",\n",
    "    \"TC\": \"Ty Cobb Stats.csv\",\n",
    "    \"WM\": \"Willie Mays Stats.csv\",\n",
    "    \"SM\": \"Stan Musial Stats.csv\",\n",
    "    \"AP\": \"Albert Pujols Stats.csv\",\n",
    "    \"PR\": \"Pete Rose Stats.csv\",\n",
    "    \"BR\": \"Babe Ruth Stats.csv\",\n",
    "    \"HW\": \"Honus Wagner Stats.csv\",\n",
    "    \"TW\": \"Ted Williams Stats.csv\"\n",
    "}\n",
    "\"\"\"\n",
    "# Base directory path\n",
    "#base_dir = r\"C:\\Users\\zscon\\Desktop\\SSE_591\\repo\\SSE591_Week3\\Week 3\\Baseball Statistics\"\n",
    "base_dir = r\"C:\\Users\\Zachary.Cone.SERN\\Desktop\\SSE 591-Intro to Python & Data Science\\Week 3\\SSE591_Week3\\Week 3\\Baseball Statistics\"\n",
    "\n",
    "# List to store all the player DataFrames\n",
    "player_dataframes = {}\n",
    "all_player_dfs = []\n",
    "\n",
    "# Load data for each player into a pandas DataFrame\n",
    "for player, file_name in files.items():\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    player_df = pd.read_csv(file_path)\n",
    "    # Drop rows with any missing values (empty cells)\n",
    "    player_dataframes[player] = player_df.dropna()\n",
    "\n",
    "# Accessing Ted Williams' information\n",
    "print('Willie Mays stats without military status:\\n',player_dataframes[\"WM\"])\n",
    "print('\\nStan Musial stats without military status:\\n',player_dataframes[\"SM\"])\n",
    "print('\\nTed Williams stats without military status:\\n',player_dataframes[\"TW\"]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"HA\": \"Hank Aaron Stats.csv\",\n",
    "    \"BB\": \"Barry Bonds Stats.csv\",\n",
    "    \"TC\": \"Ty Cobb Stats.csv\",\n",
    "    \"WM\": \"Willie Mays Stats.csv\",\n",
    "    \"SM\": \"Stan Musial Stats.csv\",\n",
    "    \"AP\": \"Albert Pujols Stats.csv\",\n",
    "    \"PR\": \"Pete Rose Stats.csv\",\n",
    "    \"BR\": \"Babe Ruth Stats.csv\",\n",
    "    \"HW\": \"Honus Wagner Stats.csv\",\n",
    "    \"TW\": \"Ted Williams Stats.csv\"\n",
    "}\n",
    "\n",
    "initials = [\"HA\", \"BB\", \"TC\", \"WM\", \"SM\", \"AP\", \"PR\", \"BR\", \"HW\", \"TW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year  Age    G   PA   AB    R    H  2B  3B  HR  RBI  BB  SO     BA    OBP  \\\n",
      "0   1954   20  122  509  468   58  131  27   6  13   69  28  39  0.280  0.322   \n",
      "1   1955   21  153  665  602  105  189  37   9  27  106  49  61  0.314  0.366   \n",
      "2   1956   22  153  660  609  106  200  34  14  26   92  37  54  0.328  0.365   \n",
      "3   1957   23  151  675  615  118  198  27   6  44  132  57  58  0.322  0.378   \n",
      "4   1958   24  153  664  601  109  196  34   4  30   95  59  49  0.326  0.386   \n",
      "5   1959   25  154  693  629  116  223  46   7  39  123  51  54  0.355  0.401   \n",
      "6   1960   26  153  664  590  102  172  20  11  40  126  60  63  0.292  0.352   \n",
      "7   1961   27  155  671  603  115  197  39  10  34  120  56  64  0.327  0.381   \n",
      "8   1962   28  156  667  592  127  191  28   6  45  128  66  73  0.323  0.390   \n",
      "9   1963   29  161  714  631  121  201  29   4  44  130  78  94  0.319  0.391   \n",
      "10  1964   30  145  634  570  103  187  30   2  24   95  62  46  0.328  0.393   \n",
      "11  1965   31  150  639  570  109  181  40   1  32   89  60  81  0.318  0.379   \n",
      "12  1966   32  158  688  603  117  168  23   1  44  127  76  96  0.279  0.356   \n",
      "13  1967   33  155  669  600  113  184  37   3  39  109  63  97  0.307  0.369   \n",
      "14  1968   34  160  676  606   84  174  33   4  29   86  64  62  0.287  0.354   \n",
      "15  1969   35  147  639  547  100  164  30   3  44   97  87  47  0.300  0.396   \n",
      "16  1970   36  150  598  516  103  154  26   1  38  118  74  63  0.298  0.385   \n",
      "17  1971   37  139  573  495   95  162  22   3  47  118  71  58  0.327  0.410   \n",
      "18  1972   38  129  545  449   75  119  10   0  34   77  92  55  0.265  0.390   \n",
      "19  1973   39  120  465  392   84  118  12   1  40   96  68  51  0.301  0.402   \n",
      "20  1974   40  112  382  340   47   91  16   0  20   69  39  29  0.268  0.341   \n",
      "21  1975   41  137  543  465   45  109  16   2  12   60  70  51  0.234  0.332   \n",
      "22  1976   42   85  308  271   22   62   8   0  10   35  35  38  0.229  0.315   \n",
      "\n",
      "      SLG    OPS  OPS+   TB  \n",
      "0   0.447  0.769   104  209  \n",
      "1   0.540  0.906   141  325  \n",
      "2   0.558  0.923   151  340  \n",
      "3   0.600  0.978   166  369  \n",
      "4   0.546  0.931   153  328  \n",
      "5   0.636  1.037   183  400  \n",
      "6   0.566  0.919   156  334  \n",
      "7   0.594  0.974   163  358  \n",
      "8   0.618  1.008   170  366  \n",
      "9   0.586  0.977   179  370  \n",
      "10  0.514  0.907   153  293  \n",
      "11  0.560  0.938   161  319  \n",
      "12  0.539  0.895   142  325  \n",
      "13  0.573  0.943   168  344  \n",
      "14  0.498  0.852   153  302  \n",
      "15  0.607  1.003   177  332  \n",
      "16  0.574  0.958   149  296  \n",
      "17  0.669  1.079   194  331  \n",
      "18  0.514  0.904   147  231  \n",
      "19  0.643  1.045   177  252  \n",
      "20  0.491  0.832   128  167  \n",
      "21  0.355  0.687    95  165  \n",
      "22  0.369  0.684   102  100  \n"
     ]
    }
   ],
   "source": [
    "print(HA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AB       R       H     2B     3B     HR     RBI\n",
      "PR  14053.0  2165.0  4256.0  746.0  135.0  160.0  1314.0\n",
      "TC  11440.0  2245.0  4189.0  724.0  295.0  117.0  1944.0\n",
      "HA  12364.0  2174.0  3771.0  624.0   98.0  755.0  2297.0\n",
      "SM  10972.0  1949.0  3630.0  725.0  177.0  475.0  1951.0\n",
      "AP  11696.0  1943.0  3449.0  689.0   16.0  720.0  2268.0\n",
      "HW  10439.0  1739.0  3420.0  643.0  252.0  101.0  1732.0\n",
      "WM  10881.0  2062.0  3283.0  523.0  140.0  660.0  1903.0\n",
      "BB   9847.0  2227.0  2935.0  601.0   77.0  762.0  1996.0\n",
      "BR   8399.0  2174.0  2873.0  506.0  136.0  714.0  2214.0\n",
      "TW   7706.0  1798.0  2654.0  525.0   71.0  521.0  1839.0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "# Load data for each player into a pandas DataFrame\n",
    "for player_df in Player_DF_List:\n",
    "    # Removing \n",
    "    player_info = player_df.dropna()\n",
    "    # Selecting columns \"AB\" to \"RBI\"\n",
    "    selected_df = player_info.loc[:, \"AB\":\"RBI\"]\n",
    "    # Summing the selected columns\n",
    "    sum_result = selected_df.sum()\n",
    "    # Transpose the DataFrame\n",
    "    transposed_df = sum_result.to_frame().transpose()\n",
    "    # Set the headers as the items in .loc slice\n",
    "    transposed_df.columns = selected_df.columns\n",
    "    # Replace the zero index with the player's name\n",
    "    transposed_df.rename(index={0: initials[i]}, inplace=True)\n",
    "    # Append the transposed DataFrame to the list\n",
    "    all_player_dfs.append(transposed_df)\n",
    "    i += 1\n",
    "    \n",
    "# Concatenate all the player DataFrames into one DataFrame\n",
    "merged_df = pd.concat(all_player_dfs)\n",
    "merged_df = merged_df.sort_values(by=\"H\", ascending=False)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AB       R       H     2B     3B     HR     RBI\n",
      "TW   9847.0  2227.0  2935.0  601.0   77.0  762.0  1996.0\n",
      "TW  12364.0  2174.0  3771.0  624.0   98.0  755.0  2297.0\n",
      "TW  11696.0  1943.0  3449.0  689.0   16.0  720.0  2268.0\n",
      "TW   8399.0  2174.0  2873.0  506.0  136.0  714.0  2214.0\n",
      "TW  10881.0  2062.0  3283.0  523.0  140.0  660.0  1903.0\n",
      "TW   7706.0  1798.0  2654.0  525.0   71.0  521.0  1839.0\n",
      "TW  10972.0  1949.0  3630.0  725.0  177.0  475.0  1951.0\n",
      "TW  14053.0  2165.0  4256.0  746.0  135.0  160.0  1314.0\n",
      "TW  11440.0  2245.0  4189.0  724.0  295.0  117.0  1944.0\n",
      "TW  10439.0  1739.0  3420.0  643.0  252.0  101.0  1732.0\n"
     ]
    }
   ],
   "source": [
    "# Load data for each player into a pandas DataFrame\n",
    "for player, file_name in files.items():\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    player_df = pd.read_csv(file_path)\n",
    "    # Selecting columns \"AB\" to \"RBI\"\n",
    "    selected_df = player_df.loc[:, \"AB\":\"RBI\"]\n",
    "    # Summing the selected columns\n",
    "    sum_result = selected_df.sum()\n",
    "    # Transpose the DataFrame\n",
    "    transposed_df = sum_result.to_frame().transpose()\n",
    "    # Set the headers as the items in .loc slice\n",
    "    transposed_df.columns = selected_df.columns\n",
    "    # Replace the zero index with the player's name\n",
    "    transposed_df.rename(index={0: player}, inplace=True)\n",
    "    # Append the transposed DataFrame to the list\n",
    "    all_player_dfs.append(transposed_df)\n",
    "\n",
    "# Concatenate all the player DataFrames into one DataFrame\n",
    "merged_df = merged_df.sort_values(by = \"HR\",ascending=False)\n",
    "print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
